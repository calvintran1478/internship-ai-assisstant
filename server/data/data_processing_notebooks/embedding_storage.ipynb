{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1af0f46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\sande\\OneDrive\\Bureau\\UofT\\CSC2701_Communication4CS\\internship-ai-assisstant\\server\\data\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import os.path as op\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Constants\n",
    "PROCESSED_DIR = \"processed_data\"\n",
    "\n",
    "# Ensure we are in the correct working directory\n",
    "current_dir = os.getcwd()\n",
    "if op.basename(current_dir) == \"data_processing_notebooks\":\n",
    "    os.chdir(\"..\")\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b423de43",
   "metadata": {},
   "source": [
    "The goal of this notebook is to prepare the data for RAG. We do this via 2 big steps:\n",
    "1. Creating the embeddings for each of the stored code chunks\n",
    "2. Storing them in some vector database\n",
    "\n",
    "## 1. Creating the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75bbab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Load the data\n",
    "date_file_to_load = \"20251111\"\n",
    "datafile_to_load = f\"rag_ready_docs_{date_file_to_load}.jsonl\"\n",
    "\n",
    "def load_jsonl_docs(path):\n",
    "    docs = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                item = json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Skipping bad line: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Extract and clean text\n",
    "            text = item.get(\"text\", \"\")\n",
    "            # Remove accidental prefixes like \"page_content='...'\"\n",
    "            text = re.sub(r\"^page_content='\", \"\", text)\n",
    "            # Remove leftover quotes, 'metadata=...' artifacts, etc.\n",
    "            text = re.sub(r\"' metadata=.*$\", \"\", text)\n",
    "            text = text.strip(\" '\")\n",
    "\n",
    "            docs.append({\n",
    "                \"id\": item.get(\"id\"),\n",
    "                \"text\": text,\n",
    "                \"metadata\": item.get(\"metadata\", {})\n",
    "            })\n",
    "    return docs\n",
    "\n",
    "# Usage\n",
    "rag_docs = load_jsonl_docs(op.join(PROCESSED_DIR, datafile_to_load))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba9bea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 27/27 [00:18<00:00,  1.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1.2 Create embeddings\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\") # compact, fast model for creating embeddings\n",
    "texts = [d[\"text\"] for d in rag_docs]\n",
    "embeddings = model.encode(texts, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de60a4d9",
   "metadata": {},
   "source": [
    "## 2. Store them in a Chroma database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce7de1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the client\n",
    "client = chromadb.Client(Settings(\n",
    "    persist_directory=\"./chroma_db\"  # folder where vectors will be stored\n",
    "))\n",
    "\n",
    "# Create or get a collection\n",
    "collection = client.get_or_create_collection(name=\"chatbot_resources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f359a960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean metadata \n",
    "def clean_metadata(meta):\n",
    "    \"\"\"Remove None values and ensure all metadata values are simple strings.\"\"\"\n",
    "    if not isinstance(meta, dict):\n",
    "        return {}\n",
    "    clean = {}\n",
    "    for k, v in meta.items():\n",
    "        if v is None:\n",
    "            continue\n",
    "        # Convert everything to string\n",
    "        clean[k] = str(v)\n",
    "    return clean\n",
    "clean_metadatas = [clean_metadata(d.get(\"metadata\", {})) for d in rag_docs]\n",
    "\n",
    "# Add data to Chroma\n",
    "collection.add(\n",
    "    ids=[d[\"id\"] for d in rag_docs],\n",
    "    embeddings=embeddings.tolist(),\n",
    "    metadatas=clean_metadatas,\n",
    "    documents=texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9fca61",
   "metadata": {},
   "source": [
    "## 3. Sanity check : retrieval test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "850c1e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result 1:\n",
      "practice interview questions Rehearse story, practice question, review mistake. Wake up and have breakfast, be on time, be conﬁdent, talk out loud Questions? Comments? For more questions and comments Daniel Giovannini, PhD Associate Director, MScAC Partnerships MSc in Applied Computing (MScAC) Program University of Toronto, 9th Floor, 700 University Avenue  dgiovannini@cs.toronto.edu  416-978-1679 ...\n",
      "\n",
      "Result 2:\n",
      "you got into this industry that you wish someone had told you? What questions should I ask in an informational interview? Informational interviews and networking MScAC Talks: monthly seminar series, September to June (mscac.utoronto.ca/talks)  Applied Research in Action (ARIA): November 13th, 2025  MScAC Partner Events: starting October 2025 (dates TBA)  MScAC Internship Expo: week beginning Janua ...\n",
      "\n",
      "Result 3:\n",
      "https://firecode.io/, Gayle Laakmann McDowell resources: https://www.gayle.com/consulting, Python Tutor: https://pythontutor.com/,Technical interview external resources #2:  Pramp: https://www.pramp.com/#/, Vault: https://www.thebalancemoney.com/top-technical-interview-questions-2061227#toc-top-50-technical-interview-questions, Simplilearn: https://vault.com/blogs/interviewing/29-technical-intervi ...\n"
     ]
    }
   ],
   "source": [
    "query = \"Help me for technical interviews?\"\n",
    "query_embedding = model.encode([query])\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=query_embedding.tolist(),\n",
    "    n_results=3\n",
    ")\n",
    "\n",
    "for i, doc in enumerate(results[\"documents\"][0]):\n",
    "    print(f\"\\nResult {i+1}:\")\n",
    "    print(doc[:400], \"...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
